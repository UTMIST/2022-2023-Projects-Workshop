{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project workshop #4: Hand Guestures Recognition!\n",
        "\n",
        "Hey guys, we are actually building something neat from scratch level this time!\n",
        "This time we are not aiming to build something that is prebuilt, but instead we are trying to create something that is from the model level, To be specific, we are building a CNN classification algorithm that could classify some simple American Hand Gesture Language.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://www.lifeprint.com/asl101/fingerspelling/images/signlanguageabc.jpg\" width=\"400\"/>\n",
        "</div>"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "wf-O6IK25Koh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import\n",
        "\n",
        "First just get your library ready, running the below cell should be sufficient. Notice that you would need to install torch and tqdm first if you are running this on your local machine.\n"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "1zjol7sb5Koj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "h3Z3Iosg5Kok"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from tqdm.auto import tqdm\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "!git clone https://github.com/UTMIST/2022-2023-Projects-Workshop.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing\n",
        "\n",
        "First load your data in the zip folder named `img`.  The `img` data sets which is constructed with 9 folders which each contains 833-865 sets of image data (see figure for the detail class compositions). Considering the total dataset size is not relatively large, it would be ideal if most of the data is used for image training instead of model evaluations/ parameter tuning. Therefore, think about what train-validation-test spilt could be in this case :)"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "OC8m2lNu5Kol"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def print_folder_structure(directory):\n",
        "    \"\"\" Printing original structure of the folder\n",
        "    and returns the number of images contained in each folder as a list.\n",
        "\n",
        "    Args:\n",
        "        directory: A string of home directory path that contains\n",
        "                    the unzipped image data files\n",
        "`\n",
        "    Returns:\n",
        "        count_list: A list of integers that are the number of images contained\n",
        "                    in each class subfolder\n",
        "\n",
        "    \"\"\"\n",
        "    total = 0\n",
        "    count_list = []\n",
        "    for folder in os.listdir(directory):\n",
        "        count = 0\n",
        "        f_path = os.path.join(directory, folder)\n",
        "        for file in os.listdir(f_path):\n",
        "            count += 1\n",
        "\n",
        "        print(folder, \" \", count)\n",
        "        total += count\n",
        "        count_list.append(count)\n",
        "\n",
        "    print(\"Total: \", total)\n",
        "    return count_list\n",
        "\n",
        "\n",
        "def data_loader(data_folder, class_num, batch_size):\n",
        "    \"\"\" Loads images data, splits the data into training, validation\n",
        "    and testing datasets. Returns data loaders for the three preprocessed datasets.\n",
        "    Args:\n",
        "        data_folder: torchvision.datasets.ImageFolder type that contains all datasets.\n",
        "        class_num: A list contains number of sample sizes of each sign class\n",
        "        batch_size: A int representing the number of samples per batch\n",
        "\n",
        "    Returns:\n",
        "        train_loader: iterable training dataset organized according to batch size\n",
        "        val_loader: iterable validation dataset organized according to batch size\n",
        "        test_loader: iterable testing dataset organized according to batch size\n",
        "\n",
        "    \"\"\"\n",
        "    train_indices, val_indices, test_indices = [], [], []\n",
        "    count = 0\n",
        "    for i in class_num:\n",
        "        train_indices.extend(list(range(count, count + int(i * 0.7))))\n",
        "        val_indices.extend(list(range(count + int(i * 0.7), count + int(i * 0.85))))\n",
        "        test_indices.extend(list(range(count + int(i * 0.85), count + i)))\n",
        "        # print(data_folder[i+count-1][1]) # for checking the end of each folder\n",
        "        count += i\n",
        "\n",
        "    np.random.seed(1000)\n",
        "    np.random.shuffle(train_indices)\n",
        "\n",
        "    train_sampler = SubsetRandomSampler(train_indices)\n",
        "    train_loader_ = torch.utils.data.DataLoader(data_folder, batch_size=batch_size, num_workers=1,\n",
        "                                                sampler=train_sampler)\n",
        "    val_sampler = SubsetRandomSampler(val_indices)\n",
        "    val_loader_ = torch.utils.data.DataLoader(data_folder, batch_size=batch_size, num_workers=1, sampler=val_sampler)\n",
        "    test_sampler = SubsetRandomSampler(test_indices)\n",
        "    test_loader_ = torch.utils.data.DataLoader(data_folder, batch_size=batch_size, num_workers=1, sampler=test_sampler)\n",
        "\n",
        "    return train_loader_, val_loader_, test_loader_\n",
        "\n",
        "\n",
        "def data_visualizer(train_loader_, title):\n",
        "    \"\"\" Loads images data loaders and plots the first 15 images of the data loader.\n",
        "    This is for checking purpose.\n",
        "\n",
        "    Args:\n",
        "        train_loader_: iterable training dataset organized according to batch size\n",
        "        title: string that is the title of the resulting plots\n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure()\n",
        "    k = 0\n",
        "    for images, labels in train_loader_:\n",
        "        # since batch_size = 1, there is only 1 image in `images`\n",
        "        image = images[0]\n",
        "        # place the colour channel at the end, instead of at the beginning\n",
        "        img = np.transpose(image, [1, 2, 0])\n",
        "        # normalize pixel intensity values to [0, 1]\n",
        "        img = img / 2 + 0.5\n",
        "        plt.subplot(3, 5, k + 1)\n",
        "        plt.suptitle(title)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(img)\n",
        "\n",
        "        k += 1\n",
        "        if k > 14:\n",
        "            break"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "g5WRXjmh5Kol"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cqgmA_iR5Kol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build ur model\n",
        "\n",
        "Build a convolutional neural network model that takes the (224x224 RGB) image as input, and predicts the gesture letter. Your model should be a subclass of nn.Module."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ME2dAQ7b5Kom"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "bRLEuQfZ5Kom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build your training loops\n",
        "\n",
        "build your training codes that can train your model using user-defined parameters"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Hwez8CGV5Kom"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def get_model_name(name, batch_size, learning_rate, epoch):\n",
        "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object containing the hyperparameters\n",
        "    Returns:\n",
        "        path: A string with the hyperparameter name and value concatenated\n",
        "    \"\"\"\n",
        "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
        "                                                   batch_size,\n",
        "                                                   learning_rate,\n",
        "                                                   epoch)\n",
        "    return path\n",
        "\n",
        "\n",
        "def train(model, train_loader,val_loader, batch_size=64, l_r=0.01, num_epochs=1, use_cuda=True):\n",
        "    pass"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "zXBPixUa5Kom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "Train the model now."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "7UnUCy1A5Kom"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import gc\n",
        "# this is for cleaning the cache for the use of cuda\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ibtEXmKe5Kon"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "IFwy8JN95Kon"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "AJhEIlEu5Kon"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test your model\n",
        "\n",
        "Remember the testing set? Try using your test data_loader to test the performance of your model."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "UyPt1cpz5Kon"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "dx3NfN-Q5Kon"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jNvse_8Q5Kon"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}